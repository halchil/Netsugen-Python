# リソース指定とクラスタ管理 - PySparkの運用基礎

## 1. リソース管理の基本概念

### 1.1 なぜリソース管理が重要なのか？

```python
# 問題のある例：リソースを指定しない
from pyspark.sql import SparkSession

# デフォルト設定（問題が起きやすい）
spark = SparkSession.builder \
    .appName("MyApp") \
    .getOrCreate()

# 大きなデータを処理すると...
# df = spark.read.csv('huge_file.csv')  # メモリ不足エラー！
# java.lang.OutOfMemoryError: Java heap space
```

**問題点：**
- メモリ不足でエラー
- CPU使用率が非効率
- 処理時間が予測できない
- 他のアプリケーションに影響

### 1.2 リソース管理の基本要素

```
リソース管理の要素：
├── メモリ（Memory）
│   ├── Driver Memory: メインプログラム用
│   └── Executor Memory: 分散処理用
├── CPU（Cores）
│   ├── Driver Cores: メインプログラム用
│   └── Executor Cores: 分散処理用
└── ストレージ（Storage）
    ├── 一時ファイル
    └── キャッシュ
```

## 2. 基本的なリソース指定

### 2.1 メモリ設定

```python
from pyspark.sql import SparkSession

# 基本的なメモリ設定
spark = SparkSession.builder \
    .appName("MemoryOptimizedApp") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.driver.maxResultSize", "1g") \
    .getOrCreate()

print("メモリ設定が適用されました")
```

**設定項目の説明：**
- `spark.driver.memory`: ドライバープログラムのメモリ
- `spark.executor.memory`: 各エグゼキュータのメモリ
- `spark.driver.maxResultSize`: ドライバーに返せる最大サイズ

### 2.2 CPU設定

```python
from pyspark.sql import SparkSession

# CPU設定
spark = SparkSession.builder \
    .appName("CPUOptimizedApp") \
    .config("spark.driver.cores", "2") \
    .config("spark.executor.cores", "4") \
    .config("spark.default.parallelism", "8") \
    .getOrCreate()

print("CPU設定が適用されました")
```

**設定項目の説明：**
- `spark.driver.cores`: ドライバーのCPUコア数
- `spark.executor.cores`: 各エグゼキュータのCPUコア数
- `spark.default.parallelism`: デフォルトの並列度

### 2.3 統合的なリソース設定

```python
from pyspark.sql import SparkSession

# 統合的なリソース設定
spark = SparkSession.builder \
    .appName("OptimizedApp") \
    # メモリ設定
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.driver.maxResultSize", "1g") \
    # CPU設定
    .config("spark.driver.cores", "2") \
    .config("spark.executor.cores", "4") \
    .config("spark.default.parallelism", "8") \
    # パフォーマンス設定
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .getOrCreate()

print("統合的なリソース設定が適用されました")
```

## 3. クラスタ管理の基本

### 3.1 ローカルモード（開発用）

```python
from pyspark.sql import SparkSession

# ローカルモード（単一マシン）
spark = SparkSession.builder \
    .appName("LocalModeApp") \
    .master("local[*]") \  # ローカルモード
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .getOrCreate()

print("ローカルモードで実行中")
print("利用可能なコア数:", spark.sparkContext.defaultParallelism)
```

### 3.2 スタンドアロンモード（小規模クラスタ）

```python
from pyspark.sql import SparkSession

# スタンドアロンモード
spark = SparkSession.builder \
    .appName("StandaloneApp") \
    .master("spark://master:7077") \  # マスターのアドレス
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.executor.instances", "3") \  # エグゼキュータ数
    .getOrCreate()

print("スタンドアロンモードで実行中")
```

### 3.3 YARNモード（大規模クラスタ）

```python
from pyspark.sql import SparkSession

# YARNモード
spark = SparkSession.builder \
    .appName("YARNApp") \
    .master("yarn") \  # YARNクラスタ
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.executor.instances", "5") \
    .config("spark.executor.cores", "4") \
    .getOrCreate()

print("YARNモードで実行中")
```

## 4. リソース監視と最適化

### 4.1 リソース使用状況の確認

```python
from pyspark.sql import SparkSession

# SparkSessionを作成
spark = SparkSession.builder \
    .appName("ResourceMonitoring") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()

# リソース情報の表示
print("=== リソース情報 ===")
print("アプリケーション名:", spark.conf.get("spark.app.name"))
print("ドライバーメモリ:", spark.conf.get("spark.driver.memory"))
print("エグゼキュータメモリ:", spark.conf.get("spark.executor.memory"))
print("デフォルト並列度:", spark.sparkContext.defaultParallelism)

# 利用可能なリソース
sc = spark.sparkContext
print("利用可能なコア数:", sc.defaultParallelism)
print("アクティブなエグゼキュータ数:", len(sc._jsc.sc().statusTracker().getExecutorMetrics()))
```

### 4.2 メモリ使用量の監視

```python
from pyspark.sql import SparkSession
import time

# SparkSessionを作成
spark = SparkSession.builder \
    .appName("MemoryMonitoring") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()

# サンプルデータを作成
data = [(i, f"data_{i}") for i in range(1000000)]
df = spark.createDataFrame(data, ["id", "value"])

# メモリ使用量を監視
print("=== メモリ使用量監視 ===")
print("処理開始前のメモリ使用量を確認してください")

# 処理実行
result = df.groupBy("value").count()
result.show()

print("処理完了後のメモリ使用量を確認してください")
```

## 5. パフォーマンス最適化

### 5.1 パーティション数の最適化

```python
from pyspark.sql import SparkSession

# SparkSessionを作成
spark = SparkSession.builder \
    .appName("PartitionOptimization") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.sql.adaptive.enabled", "true") \
    .getOrCreate()

# サンプルデータを作成
data = [(i, f"category_{i % 10}") for i in range(1000000)]
df = spark.createDataFrame(data, ["id", "category"])

# パーティション数の確認
print("元のパーティション数:", df.rdd.getNumPartitions())

# パーティション数を調整
df_repartitioned = df.repartition(10)
print("調整後のパーティション数:", df_repartitioned.rdd.getNumPartitions())

# 処理実行
result = df_repartitioned.groupBy("category").count()
result.show()
```

### 5.2 キャッシュの活用

```python
from pyspark.sql import SparkSession

# SparkSessionを作成
spark = SparkSession.builder \
    .appName("CacheOptimization") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()

# サンプルデータを作成
data = [(i, f"category_{i % 10}") for i in range(1000000)]
df = spark.createDataFrame(data, ["id", "category"])

# キャッシュを有効化
df.cache()

# 複数回の処理（キャッシュ効果を確認）
print("=== 1回目の処理 ===")
start_time = time.time()
result1 = df.groupBy("category").count()
result1.show()
print(f"1回目の処理時間: {time.time() - start_time:.2f}秒")

print("\n=== 2回目の処理（キャッシュ効果） ===")
start_time = time.time()
result2 = df.groupBy("category").avg("id")
result2.show()
print(f"2回目の処理時間: {time.time() - start_time:.2f}秒")

# キャッシュを解放
df.unpersist()
```

## 6. クラスタ設定の実践例

### 6.1 開発環境の設定

```python
from pyspark.sql import SparkSession

# 開発環境用設定
spark = SparkSession.builder \
    .appName("DevelopmentApp") \
    .master("local[*]") \
    .config("spark.driver.memory", "1g") \
    .config("spark.executor.memory", "1g") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .config("spark.sql.adaptive.skewJoin.enabled", "true") \
    .getOrCreate()

print("開発環境用設定で実行中")
```

### 6.2 本番環境の設定

```python
from pyspark.sql import SparkSession

# 本番環境用設定
spark = SparkSession.builder \
    .appName("ProductionApp") \
    .master("yarn") \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "8g") \
    .config("spark.executor.instances", "10") \
    .config("spark.executor.cores", "4") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .config("spark.sql.adaptive.skewJoin.enabled", "true") \
    .config("spark.sql.adaptive.localShuffleReader.enabled", "true") \
    .config("spark.sql.adaptive.advisoryPartitionSizeInBytes", "128m") \
    .getOrCreate()

print("本番環境用設定で実行中")
```

## 7. トラブルシューティング

### 7.1 メモリ不足エラー

```python
# エラー例
# java.lang.OutOfMemoryError: Java heap space

# 解決策
spark = SparkSession.builder \
    .appName("MemoryOptimizedApp") \
    .config("spark.driver.memory", "4g") \  # 増加
    .config("spark.executor.memory", "8g") \  # 増加
    .config("spark.driver.maxResultSize", "2g") \  # 増加
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .getOrCreate()
```

### 7.2 処理時間が長い

```python
# 解決策
spark = SparkSession.builder \
    .appName("PerformanceOptimizedApp") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.executor.cores", "4") \  # CPUコア数を増加
    .config("spark.default.parallelism", "16") \  # 並列度を増加
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .config("spark.sql.adaptive.skewJoin.enabled", "true") \
    .getOrCreate()
```

### 7.3 ネットワーク通信が多い

```python
# 解決策
spark = SparkSession.builder \
    .appName("NetworkOptimizedApp") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.sql.adaptive.enabled", "true") \
    .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
    .config("spark.sql.adaptive.localShuffleReader.enabled", "true") \  # ローカルシャッフル
    .config("spark.sql.adaptive.advisoryPartitionSizeInBytes", "128m") \  # パーティションサイズ最適化
    .getOrCreate()
```

## 8. 練習問題

### 練習1: リソース設定の最適化

```python
from pyspark.sql import SparkSession
import time

# 以下の要件でSparkSessionを作成してください
# - アプリケーション名: "MyOptimizedApp"
# - ドライバーメモリ: 2GB
# - エグゼキュータメモリ: 4GB
# - エグゼキュータコア数: 2
# - パフォーマンス最適化を有効化

# ここにコードを書いてください

# サンプルデータで処理時間を測定
data = [(i, f"category_{i % 5}") for i in range(500000)]
df = spark.createDataFrame(data, ["id", "category"])

start_time = time.time()
result = df.groupBy("category").agg({"id": "count", "id": "avg"})
result.show()
print(f"処理時間: {time.time() - start_time:.2f}秒")
```

### 練習2: クラスタ設定の設計

```python
# 以下の要件でクラスタ設定を設計してください
# - データ量: 1TB
# - 処理時間: 30分以内
# - 予算: 月50万円以内
# - 可用性: 99.9%

def design_cluster_config():
    # 必要なマシン台数
    # 各マシンのスペック
    # メモリ設定
    # CPU設定
    # ネットワーク設定
    pass
```

## 9. まとめ

この章で学んだこと：
- リソース管理の基本概念
- メモリとCPUの設定方法
- クラスタ管理の基本
- パフォーマンス最適化
- トラブルシューティング

次のステップ：
- より高度なクラスタ管理
- 監視・ログ分析
- セキュリティ設定
- 運用自動化

**重要：** リソース設定は慎重に行い、実際の負荷でテストすることが大切です！ 